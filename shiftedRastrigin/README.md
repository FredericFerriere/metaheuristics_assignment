# Shifted Rosenbrock

## How to run the code

The notebook is self contained:
* The function to optimise is implemented in the file functionToOptimise.py  
* Libraries needed: numpy, scipy

## Algorithm

XXXXXX

## Dimension 50

### Parameters

XXXX

Stopping criterion: || gradient || < tol, with tol=1e-2 and infinity norm.

### Results

Optimum found: XXX (known optimum -330)

number of function evaluations: X

computational Time: X s

convergence curve

![](convergenceCurve_dim_50.png)

## Dimension 500

### Parameters

XXX

Stopping criterion: || gradient || < tol, with tol=1e-2 and infinity norm.

### Results

Optimum found: X (known optimum -330)

number of function evaluations: X

computational Time: x s

convergence curve

![](convergenceCurve_dim_500.png)
